{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EDNujY13XBTD"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import csv\n",
        "import math\n",
        "import heapq\n",
        "import random\n",
        "import itertools\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "from surprise import accuracy\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "from surprise import AlgoBase\n",
        "from surprise import PredictionImpossible\n",
        "from surprise import NormalPredictor\n",
        "from surprise import KNNBaseline\n",
        "from surprise import SVD, SVDpp\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise.model_selection import LeaveOneOut"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eT7McFtmWkd2"
      },
      "outputs": [],
      "source": [
        "class MovieLens:\n",
        "\n",
        "    movieID_to_name = {}\n",
        "    name_to_movieID = {}\n",
        "    ratingsPath = 'ml-latest-small/ratings.csv'\n",
        "    moviesPath = 'ml-latest-small/movies.csv'\n",
        "\n",
        "    def loadMovieLensLatestSmall(self):\n",
        "\n",
        "        ratingsDataset = 0\n",
        "        self.movieID_to_name = {}\n",
        "        self.name_to_movieID = {}\n",
        "\n",
        "        reader = Reader(line_format='user item rating timestamp', sep=',', skip_lines=1)\n",
        "\n",
        "        ratingsDataset = Dataset.load_from_file(self.ratingsPath, reader=reader)\n",
        "\n",
        "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "                movieReader = csv.reader(csvfile)\n",
        "                next(movieReader)  #Skip header line\n",
        "                for row in movieReader:\n",
        "                    movieID = int(row[0])\n",
        "                    movieName = row[1]\n",
        "                    self.movieID_to_name[movieID] = movieName\n",
        "                    self.name_to_movieID[movieName] = movieID\n",
        "\n",
        "        return ratingsDataset\n",
        "\n",
        "    def getUserRatings(self, user):\n",
        "        userRatings = []\n",
        "        hitUser = False\n",
        "        with open(self.ratingsPath, newline='') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                userID = int(row[0])\n",
        "                if (user == userID):\n",
        "                    movieID = int(row[1])\n",
        "                    rating = float(row[2])\n",
        "                    userRatings.append((movieID, rating))\n",
        "                    hitUser = True\n",
        "                if (hitUser and (user != userID)):\n",
        "                    break\n",
        "\n",
        "        return userRatings\n",
        "\n",
        "    def getPopularityRanks(self):\n",
        "        ratings = defaultdict(int)\n",
        "        rankings = defaultdict(int)\n",
        "        with open(self.ratingsPath, newline='') as csvfile:\n",
        "            ratingReader = csv.reader(csvfile)\n",
        "            next(ratingReader)\n",
        "            for row in ratingReader:\n",
        "                movieID = int(row[1])\n",
        "                ratings[movieID] += 1\n",
        "        rank = 1\n",
        "        for movieID, ratingCount in sorted(ratings.items(), key=lambda x: x[1], reverse=True):\n",
        "            rankings[movieID] = rank\n",
        "            rank += 1\n",
        "        return rankings\n",
        "\n",
        "    def getGenres(self):\n",
        "        genres = defaultdict(list)\n",
        "        genreIDs = {}\n",
        "        maxGenreID = 0\n",
        "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            movieReader = csv.reader(csvfile)\n",
        "            next(movieReader)  #Skip header line\n",
        "            for row in movieReader:\n",
        "                movieID = int(row[0])\n",
        "                genreList = row[2].split('|')\n",
        "                genreIDList = []\n",
        "                for genre in genreList:\n",
        "                    if genre in genreIDs:\n",
        "                        genreID = genreIDs[genre]\n",
        "                    else:\n",
        "                        genreID = maxGenreID\n",
        "                        genreIDs[genre] = genreID\n",
        "                        maxGenreID += 1\n",
        "                    genreIDList.append(genreID)\n",
        "                genres[movieID] = genreIDList\n",
        "\n",
        "        # Convert integer-encoded genre lists to bitfields that we can treat as vectors\n",
        "        for (movieID, genreIDList) in genres.items():\n",
        "            bitfield = [0] * maxGenreID\n",
        "            for genreID in genreIDList:\n",
        "                bitfield[genreID] = 1\n",
        "            genres[movieID] = bitfield\n",
        "\n",
        "        return genres\n",
        "\n",
        "    def getYears(self):\n",
        "        p = re.compile(r\"(?:\\((\\d{4})\\))?\\s*$\")\n",
        "        years = defaultdict(int)\n",
        "        with open(self.moviesPath, newline='', encoding='ISO-8859-1') as csvfile:\n",
        "            movieReader = csv.reader(csvfile)\n",
        "            next(movieReader)\n",
        "            for row in movieReader:\n",
        "                movieID = int(row[0])\n",
        "                title = row[1]\n",
        "                m = p.search(title)\n",
        "                year = m.group(1)\n",
        "                if year:\n",
        "                    years[movieID] = int(year)\n",
        "        return years\n",
        "\n",
        "    def getMiseEnScene(self):\n",
        "        mes = defaultdict(list)\n",
        "        with open(\"LLVisualFeatures13K_Log.csv\", newline='') as csvfile:\n",
        "            mesReader = csv.reader(csvfile)\n",
        "            next(mesReader)\n",
        "            for row in mesReader:\n",
        "                movieID = int(row[0])\n",
        "                avgShotLength = float(row[1])\n",
        "                meanColorVariance = float(row[2])\n",
        "                stddevColorVariance = float(row[3])\n",
        "                meanMotion = float(row[4])\n",
        "                stddevMotion = float(row[5])\n",
        "                meanLightingKey = float(row[6])\n",
        "                numShots = float(row[7])\n",
        "                mes[movieID] = [avgShotLength, meanColorVariance, stddevColorVariance,\n",
        "                   meanMotion, stddevMotion, meanLightingKey, numShots]\n",
        "        return mes\n",
        "\n",
        "    def getMovieName(self, movieID):\n",
        "        if movieID in self.movieID_to_name:\n",
        "            return self.movieID_to_name[movieID]\n",
        "        else:\n",
        "            return \"\"\n",
        "\n",
        "    def getMovieID(self, movieName):\n",
        "        if movieName in self.name_to_movieID:\n",
        "            return self.name_to_movieID[movieName]\n",
        "        else:\n",
        "            return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml = MovieLens()\n",
        "data = ml.loadMovieLensLatestSmall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfhfm7VoltHl"
      },
      "outputs": [],
      "source": [
        "class RecommenderMetrics:\n",
        "\n",
        "    def MAE(predictions):\n",
        "        return accuracy.mae(predictions, verbose=False)\n",
        "\n",
        "    def RMSE(predictions):\n",
        "        return accuracy.rmse(predictions, verbose=False)\n",
        "\n",
        "    def GetTopN(predictions, n=10, minimumRating=4.0):\n",
        "        topN = defaultdict(list)\n",
        "\n",
        "\n",
        "        for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
        "            if (estimatedRating >= minimumRating):\n",
        "                topN[int(userID)].append((int(movieID), estimatedRating))\n",
        "\n",
        "        for userID, ratings in topN.items():\n",
        "            ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "            topN[int(userID)] = ratings[:n]\n",
        "\n",
        "        return topN\n",
        "\n",
        "    def HitRate(topNPredicted, leftOutPredictions):\n",
        "        hits = 0\n",
        "        total = 0\n",
        "\n",
        "        # For each left-out rating\n",
        "        for leftOut in leftOutPredictions:\n",
        "            userID = leftOut[0]\n",
        "            leftOutMovieID = leftOut[1]\n",
        "            # Is it in the predicted top 10 for this user?\n",
        "            hit = False\n",
        "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                if (int(leftOutMovieID) == int(movieID)):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit) :\n",
        "                hits += 1\n",
        "\n",
        "            total += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        return hits/total\n",
        "\n",
        "    def CumulativeHitRate(topNPredicted, leftOutPredictions, ratingCutoff=0):\n",
        "        hits = 0\n",
        "        total = 0\n",
        "\n",
        "        # For each left-out rating\n",
        "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Only look at ability to recommend things the users actually liked...\n",
        "            if (actualRating >= ratingCutoff):\n",
        "                # Is it in the predicted top 10 for this user?\n",
        "                hit = False\n",
        "                for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                    if (int(leftOutMovieID) == movieID):\n",
        "                        hit = True\n",
        "                        break\n",
        "                if (hit) :\n",
        "                    hits += 1\n",
        "\n",
        "                total += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        return hits/total\n",
        "\n",
        "    def RatingHitRate(topNPredicted, leftOutPredictions):\n",
        "        hits = defaultdict(float)\n",
        "        total = defaultdict(float)\n",
        "\n",
        "        # For each left-out rating\n",
        "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Is it in the predicted top N for this user?\n",
        "            hit = False\n",
        "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                if (int(leftOutMovieID) == movieID):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit) :\n",
        "                hits[actualRating] += 1\n",
        "\n",
        "            total[actualRating] += 1\n",
        "\n",
        "        # Compute overall precision\n",
        "        for rating in sorted(hits.keys()):\n",
        "            print (rating, hits[rating] / total[rating])\n",
        "\n",
        "    def AverageReciprocalHitRank(topNPredicted, leftOutPredictions):\n",
        "        summation = 0\n",
        "        total = 0\n",
        "        # For each left-out rating\n",
        "        for userID, leftOutMovieID, actualRating, estimatedRating, _ in leftOutPredictions:\n",
        "            # Is it in the predicted top N for this user?\n",
        "            hitRank = 0\n",
        "            rank = 0\n",
        "            for movieID, predictedRating in topNPredicted[int(userID)]:\n",
        "                rank = rank + 1\n",
        "                if (int(leftOutMovieID) == movieID):\n",
        "                    hitRank = rank\n",
        "                    break\n",
        "            if (hitRank > 0) :\n",
        "                summation += 1.0 / hitRank\n",
        "\n",
        "            total += 1\n",
        "\n",
        "        return summation / total\n",
        "\n",
        "    # What percentage of users have at least one \"good\" recommendation\n",
        "    def UserCoverage(topNPredicted, numUsers, ratingThreshold=0):\n",
        "        hits = 0\n",
        "        for userID in topNPredicted.keys():\n",
        "            hit = False\n",
        "            for movieID, predictedRating in topNPredicted[userID]:\n",
        "                if (predictedRating >= ratingThreshold):\n",
        "                    hit = True\n",
        "                    break\n",
        "            if (hit):\n",
        "                hits += 1\n",
        "\n",
        "        return hits / numUsers\n",
        "\n",
        "    def Diversity(topNPredicted, simsAlgo):\n",
        "        n = 0\n",
        "        total = 0\n",
        "        simsMatrix = simsAlgo.compute_similarities()\n",
        "        for userID in topNPredicted.keys():\n",
        "            pairs = itertools.combinations(topNPredicted[userID], 2)\n",
        "            for pair in pairs:\n",
        "                movie1 = pair[0][0]\n",
        "                movie2 = pair[1][0]\n",
        "                innerID1 = simsAlgo.trainset.to_inner_iid(str(movie1))\n",
        "                innerID2 = simsAlgo.trainset.to_inner_iid(str(movie2))\n",
        "                similarity = simsMatrix[innerID1][innerID2]\n",
        "                total += similarity\n",
        "                n += 1\n",
        "\n",
        "        S = total / n\n",
        "        return (1-S)\n",
        "\n",
        "    def Novelty(topNPredicted, rankings):\n",
        "        n = 0\n",
        "        total = 0\n",
        "        for userID in topNPredicted.keys():\n",
        "            for rating in topNPredicted[userID]:\n",
        "                movieID = rating[0]\n",
        "                rank = rankings[movieID]\n",
        "                total += rank\n",
        "                n += 1\n",
        "        return total / n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oko5gnvpYjfV"
      },
      "outputs": [],
      "source": [
        "class EvaluationData:\n",
        "\n",
        "    def __init__(self, data, popularityRankings):\n",
        "\n",
        "        self.rankings = popularityRankings\n",
        "\n",
        "        #Build a full training set for evaluating overall properties\n",
        "        self.fullTrainSet = data.build_full_trainset()\n",
        "        self.fullAntiTestSet = self.fullTrainSet.build_anti_testset()\n",
        "\n",
        "        #Build a 75/25 train/test split for measuring accuracy\n",
        "        self.trainSet, self.testSet = train_test_split(data, test_size=.25, random_state=1)\n",
        "\n",
        "        #Build a \"leave one out\" train/test split for evaluating top-N recommenders\n",
        "        #And build an anti-test-set for building predictions\n",
        "        LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
        "        for train, test in LOOCV.split(data):\n",
        "            self.LOOCVTrain = train\n",
        "            self.LOOCVTest = test\n",
        "\n",
        "        self.LOOCVAntiTestSet = self.LOOCVTrain.build_anti_testset()\n",
        "\n",
        "        #Compute similarty matrix between items so we can measure diversity\n",
        "        sim_options = {'name': 'cosine', 'user_based': False}\n",
        "        self.simsAlgo = KNNBaseline(sim_options=sim_options)\n",
        "        self.simsAlgo.fit(self.fullTrainSet)\n",
        "\n",
        "    def GetFullTrainSet(self):\n",
        "        return self.fullTrainSet\n",
        "\n",
        "    def GetFullAntiTestSet(self):\n",
        "        return self.fullAntiTestSet\n",
        "\n",
        "    def GetAntiTestSetForUser(self, testSubject):\n",
        "        trainset = self.fullTrainSet\n",
        "        fill = trainset.global_mean\n",
        "        anti_testset = []\n",
        "        u = trainset.to_inner_uid(str(testSubject))\n",
        "        user_items = set([j for (j, _) in trainset.ur[u]])\n",
        "        anti_testset += [(trainset.to_raw_uid(u), trainset.to_raw_iid(i), fill) for\n",
        "                                 i in trainset.all_items() if\n",
        "                                 i not in user_items]\n",
        "        return anti_testset\n",
        "\n",
        "    def GetTrainSet(self):\n",
        "        return self.trainSet\n",
        "\n",
        "    def GetTestSet(self):\n",
        "        return self.testSet\n",
        "\n",
        "    def GetLOOCVTrainSet(self):\n",
        "        return self.LOOCVTrain\n",
        "\n",
        "    def GetLOOCVTestSet(self):\n",
        "        return self.LOOCVTest\n",
        "\n",
        "    def GetLOOCVAntiTestSet(self):\n",
        "        return self.LOOCVAntiTestSet\n",
        "\n",
        "    def GetSimilarities(self):\n",
        "        return self.simsAlgo\n",
        "\n",
        "    def GetPopularityRankings(self):\n",
        "        return self.rankings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJsWmhP_mEev"
      },
      "outputs": [],
      "source": [
        "class EvaluatedAlgorithm:\n",
        "\n",
        "    def __init__(self, algorithm, name):\n",
        "        self.algorithm = algorithm\n",
        "        self.name = name\n",
        "\n",
        "    def Evaluate(self, evaluationData, doTopN, n=10, verbose=True):\n",
        "        metrics = {}\n",
        "        # Compute accuracy\n",
        "        if (verbose):\n",
        "            print(\"Evaluating accuracy...\")\n",
        "        self.algorithm.fit(evaluationData.GetTrainSet())\n",
        "        predictions = self.algorithm.test(evaluationData.GetTestSet())\n",
        "        metrics[\"RMSE\"] = RecommenderMetrics.RMSE(predictions)\n",
        "        metrics[\"MAE\"] = RecommenderMetrics.MAE(predictions)\n",
        "\n",
        "        if (doTopN):\n",
        "            # Evaluate top-10 with Leave One Out testing\n",
        "            if (verbose):\n",
        "                print(\"Evaluating top-N with leave-one-out...\")\n",
        "            self.algorithm.fit(evaluationData.GetLOOCVTrainSet())\n",
        "            leftOutPredictions = self.algorithm.test(evaluationData.GetLOOCVTestSet())\n",
        "            # Build predictions for all ratings not in the training set\n",
        "            allPredictions = self.algorithm.test(evaluationData.GetLOOCVAntiTestSet())\n",
        "            # Compute top 10 recs for each user\n",
        "            topNPredicted = RecommenderMetrics.GetTopN(allPredictions, n)\n",
        "            if (verbose):\n",
        "                print(\"Computing hit-rate and rank metrics...\")\n",
        "            # See how often we recommended a movie the user actually rated\n",
        "            metrics[\"HR\"] = RecommenderMetrics.HitRate(topNPredicted, leftOutPredictions)\n",
        "            # See how often we recommended a movie the user actually liked\n",
        "            metrics[\"cHR\"] = RecommenderMetrics.CumulativeHitRate(topNPredicted, leftOutPredictions)\n",
        "            # Compute ARHR\n",
        "            metrics[\"ARHR\"] = RecommenderMetrics.AverageReciprocalHitRank(topNPredicted, leftOutPredictions)\n",
        "\n",
        "            #Evaluate properties of recommendations on full training set\n",
        "            if (verbose):\n",
        "                print(\"Computing recommendations with full data set...\")\n",
        "            self.algorithm.fit(evaluationData.GetFullTrainSet())\n",
        "            allPredictions = self.algorithm.test(evaluationData.GetFullAntiTestSet())\n",
        "            topNPredicted = RecommenderMetrics.GetTopN(allPredictions, n)\n",
        "            if (verbose):\n",
        "                print(\"Analyzing coverage, diversity, and novelty...\")\n",
        "            # Print user coverage with a minimum predicted rating of 4.0:\n",
        "            metrics[\"Coverage\"] = RecommenderMetrics.UserCoverage(  topNPredicted,\n",
        "                                                                   evaluationData.GetFullTrainSet().n_users,\n",
        "                                                                   ratingThreshold=4.0)\n",
        "            # Measure diversity of recommendations:\n",
        "            metrics[\"Diversity\"] = RecommenderMetrics.Diversity(topNPredicted, evaluationData.GetSimilarities())\n",
        "\n",
        "            # Measure novelty (average popularity rank of recommendations):\n",
        "            metrics[\"Novelty\"] = RecommenderMetrics.Novelty(topNPredicted,\n",
        "                                                            evaluationData.GetPopularityRankings())\n",
        "\n",
        "        if (verbose):\n",
        "            print(\"Analysis complete.\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def GetName(self):\n",
        "        return self.name\n",
        "\n",
        "    def GetAlgorithm(self):\n",
        "        return self.algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lfBwFwRmPmH"
      },
      "outputs": [],
      "source": [
        "class Evaluator:\n",
        "\n",
        "    algorithms = []\n",
        "\n",
        "    def __init__(self, dataset, rankings):\n",
        "        ed = EvaluationData(dataset, rankings)\n",
        "        self.dataset = ed\n",
        "\n",
        "    def AddAlgorithm(self, algorithm, name):\n",
        "        alg = EvaluatedAlgorithm(algorithm, name)\n",
        "        self.algorithms.append(alg)\n",
        "\n",
        "    def Evaluate(self, doTopN):\n",
        "        results = {}\n",
        "        for algorithm in self.algorithms:\n",
        "            print(\"Evaluating \", algorithm.GetName(), \"...\")\n",
        "            results[algorithm.GetName()] = algorithm.Evaluate(self.dataset, doTopN)\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\n\")\n",
        "\n",
        "        if (doTopN):\n",
        "            print(\"{:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(\n",
        "                    \"Algorithm\", \"RMSE\", \"MAE\", \"HR\", \"cHR\", \"ARHR\", \"Coverage\", \"Diversity\", \"Novelty\"))\n",
        "            for (name, metrics) in results.items():\n",
        "                print(\"{:<10} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f}\".format(\n",
        "                        name, metrics[\"RMSE\"], metrics[\"MAE\"], metrics[\"HR\"], metrics[\"cHR\"], metrics[\"ARHR\"],\n",
        "                                      metrics[\"Coverage\"], metrics[\"Diversity\"], metrics[\"Novelty\"]))\n",
        "        else:\n",
        "            print(\"{:<10} {:<10} {:<10}\".format(\"Algorithm\", \"RMSE\", \"MAE\"))\n",
        "            for (name, metrics) in results.items():\n",
        "                print(\"{:<10} {:<10.4f} {:<10.4f}\".format(name, metrics[\"RMSE\"], metrics[\"MAE\"]))\n",
        "\n",
        "        print(\"\\nLegend:\\n\")\n",
        "        print(\"RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\")\n",
        "        print(\"MAE:       Mean Absolute Error. Lower values mean better accuracy.\")\n",
        "        if (doTopN):\n",
        "            print(\"HR:        Hit Rate; how often we are able to recommend a left-out rating. Higher is better.\")\n",
        "            print(\"cHR:       Cumulative Hit Rate; hit rate, confined to ratings above a certain threshold. Higher is better.\")\n",
        "            print(\"ARHR:      Average Reciprocal Hit Rank - Hit rate that takes the ranking into account. Higher is better.\" )\n",
        "            print(\"Coverage:  Ratio of users for whom recommendations above a certain threshold exist. Higher is better.\")\n",
        "            print(\"Diversity: 1-S, where S is the average similarity score between every possible pair of recommendations\")\n",
        "            print(\"           for a given user. Higher means more diverse.\")\n",
        "            print(\"Novelty:   Average popularity rank of recommended items. Higher means more novel.\")\n",
        "\n",
        "    def SampleTopNRecs(self, ml, testSubject=85, k=10):\n",
        "\n",
        "        for algo in self.algorithms:\n",
        "            print(\"\\nUsing recommender \", algo.GetName())\n",
        "\n",
        "            print(\"\\nBuilding recommendation model...\")\n",
        "            trainSet = self.dataset.GetFullTrainSet()\n",
        "            algo.GetAlgorithm().fit(trainSet)\n",
        "\n",
        "            print(\"Computing recommendations...\")\n",
        "            testSet = self.dataset.GetAntiTestSetForUser(testSubject)\n",
        "\n",
        "            predictions = algo.GetAlgorithm().test(testSet)\n",
        "\n",
        "            recommendations = []\n",
        "\n",
        "            print (\"\\nWe recommend:\")\n",
        "            for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
        "                intMovieID = int(movieID)\n",
        "                recommendations.append((intMovieID, estimatedRating))\n",
        "\n",
        "            recommendations.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "            for ratings in recommendations[:10]:\n",
        "                print(ml.getMovieName(ratings[0]), ratings[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ydttSWBHmn_o"
      },
      "outputs": [],
      "source": [
        "class ContentKNNAlgorithm(AlgoBase):\n",
        "\n",
        "    def __init__(self, k=40, sim_options={}):\n",
        "        AlgoBase.__init__(self)\n",
        "        self.k = k\n",
        "\n",
        "    def fit(self, trainset):\n",
        "        AlgoBase.fit(self, trainset)\n",
        "\n",
        "        # Compute item similarity matrix based on content attributes\n",
        "\n",
        "        # Load up genre vectors for every movie\n",
        "        ml = MovieLens()\n",
        "        genres = ml.getGenres()\n",
        "        years = ml.getYears()\n",
        "        mes = ml.getMiseEnScene()\n",
        "\n",
        "        print(\"Computing content-based similarity matrix...\")\n",
        "\n",
        "        # Compute genre distance for every movie combination as a 2x2 matrix\n",
        "        self.similarities = np.zeros((self.trainset.n_items, self.trainset.n_items))\n",
        "\n",
        "        for thisRating in range(self.trainset.n_items):\n",
        "            if (thisRating % 100 == 0):\n",
        "                print(thisRating, \" of \", self.trainset.n_items)\n",
        "            for otherRating in range(thisRating+1, self.trainset.n_items):\n",
        "                thisMovieID = int(self.trainset.to_raw_iid(thisRating))\n",
        "                otherMovieID = int(self.trainset.to_raw_iid(otherRating))\n",
        "                genreSimilarity = self.computeGenreSimilarity(thisMovieID, otherMovieID, genres)\n",
        "                yearSimilarity = self.computeYearSimilarity(thisMovieID, otherMovieID, years)\n",
        "                self.similarities[thisRating, otherRating] = genreSimilarity * yearSimilarity\n",
        "                self.similarities[otherRating, thisRating] = self.similarities[thisRating, otherRating]\n",
        "\n",
        "        print(\"...done.\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def computeGenreSimilarity(self, movie1, movie2, genres):\n",
        "        genres1 = genres[movie1]\n",
        "        genres2 = genres[movie2]\n",
        "        sumxx, sumxy, sumyy = 0, 0, 0\n",
        "        for i in range(len(genres1)):\n",
        "            x = genres1[i]\n",
        "            y = genres2[i]\n",
        "            sumxx += x * x\n",
        "            sumyy += y * y\n",
        "            sumxy += x * y\n",
        "\n",
        "        return sumxy/math.sqrt(sumxx*sumyy)\n",
        "\n",
        "    def computeYearSimilarity(self, movie1, movie2, years):\n",
        "        diff = abs(years[movie1] - years[movie2])\n",
        "        sim = math.exp(-diff / 10.0)\n",
        "        return sim\n",
        "\n",
        "    def computeMiseEnSceneSimilarity(self, movie1, movie2, mes):\n",
        "        mes1 = mes[movie1]\n",
        "        mes2 = mes[movie2]\n",
        "        if (mes1 and mes2):\n",
        "            shotLengthDiff = math.fabs(mes1[0] - mes2[0])\n",
        "            colorVarianceDiff = math.fabs(mes1[1] - mes2[1])\n",
        "            motionDiff = math.fabs(mes1[3] - mes2[3])\n",
        "            lightingDiff = math.fabs(mes1[5] - mes2[5])\n",
        "            numShotsDiff = math.fabs(mes1[6] - mes2[6])\n",
        "            return shotLengthDiff * colorVarianceDiff * motionDiff * lightingDiff * numShotsDiff\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    def estimate(self, u, i):\n",
        "\n",
        "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
        "            raise PredictionImpossible('User and/or item is unkown.')\n",
        "\n",
        "        # Build up similarity scores between this item and everything the user rated\n",
        "        neighbors = []\n",
        "        for rating in self.trainset.ur[u]:\n",
        "            genreSimilarity = self.similarities[i,rating[0]]\n",
        "            neighbors.append( (genreSimilarity, rating[1]) )\n",
        "\n",
        "        # Extract the top-K most-similar ratings\n",
        "        k_neighbors = heapq.nlargest(self.k, neighbors, key=lambda t: t[0])\n",
        "\n",
        "        # Compute average sim score of K neighbors weighted by user ratings\n",
        "        simTotal = weightedSum = 0\n",
        "        for (simScore, rating) in k_neighbors:\n",
        "            if (simScore > 0):\n",
        "                simTotal += simScore\n",
        "                weightedSum += simScore * rating\n",
        "\n",
        "        if (simTotal == 0):\n",
        "            raise PredictionImpossible('No neighbors')\n",
        "\n",
        "        predictedRating = weightedSum / simTotal\n",
        "\n",
        "        return predictedRating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBjbMZX0m-Wl"
      },
      "outputs": [],
      "source": [
        "class RBM(object):\n",
        "\n",
        "    def __init__(self, visibleDimensions, epochs=20, hiddenDimensions=50, ratingValues=10, learningRate=0.001, batchSize=100):\n",
        "\n",
        "        self.visibleDimensions = visibleDimensions\n",
        "        self.epochs = epochs\n",
        "        self.hiddenDimensions = hiddenDimensions\n",
        "        self.ratingValues = ratingValues\n",
        "        self.learningRate = learningRate\n",
        "        self.batchSize = batchSize\n",
        "\n",
        "\n",
        "    def Train(self, X):\n",
        "\n",
        "        ops.reset_default_graph()\n",
        "\n",
        "        self.MakeGraph()\n",
        "\n",
        "        init = tf.compat.v1.global_variables_initializer()\n",
        "        self.sess = tf.compat.v1.Session()\n",
        "        self.sess.run(init)\n",
        "\n",
        "        for epoch in range(self.epochs):\n",
        "            np.random.shuffle(X)\n",
        "\n",
        "            trX = np.array(X)\n",
        "            for i in range(0, trX.shape[0], self.batchSize):\n",
        "                self.sess.run(self.update, feed_dict={self.X: trX[i:i+self.batchSize]})\n",
        "\n",
        "            print(\"Trained epoch \", epoch)\n",
        "\n",
        "\n",
        "    def GetRecommendations(self, inputUser):\n",
        "\n",
        "        hidden = tf.nn.sigmoid(tf.matmul(self.X, self.weights) + self.hiddenBias)\n",
        "        visible = tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(self.weights)) + self.visibleBias)\n",
        "\n",
        "        feed = self.sess.run(hidden, feed_dict={ self.X: inputUser} )\n",
        "        rec = self.sess.run(visible, feed_dict={ hidden: feed} )\n",
        "        return rec[0]\n",
        "\n",
        "    def MakeGraph(self):\n",
        "        tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "        tf.random.set_seed(0)\n",
        "\n",
        "        # Create variables for the graph, weights and biases\n",
        "        self.X = tf.compat.v1.placeholder(tf.float32, [None, self.visibleDimensions], name=\"X\")\n",
        "\n",
        "        # Initialize weights randomly\n",
        "        maxWeight = -4.0 * np.sqrt(6.0 / (self.hiddenDimensions + self.visibleDimensions))\n",
        "        self.weights = tf.Variable(tf.random.uniform([self.visibleDimensions, self.hiddenDimensions], minval=-maxWeight, maxval=maxWeight), tf.float32, name=\"weights\")\n",
        "\n",
        "        self.hiddenBias = tf.Variable(tf.zeros([self.hiddenDimensions], tf.float32, name=\"hiddenBias\"))\n",
        "        self.visibleBias = tf.Variable(tf.zeros([self.visibleDimensions], tf.float32, name=\"visibleBias\"))\n",
        "\n",
        "        # Perform Gibbs Sampling for Contrastive Divergence, per the paper we assume k=1 instead of iterating over the\n",
        "        # forward pass multiple times since it seems to work just fine\n",
        "\n",
        "        # Forward pass\n",
        "        # Sample hidden layer given visible...\n",
        "        # Get tensor of hidden probabilities\n",
        "        hProb0 = tf.nn.sigmoid(tf.matmul(self.X, self.weights) + self.hiddenBias)\n",
        "        # Sample from all of the distributions\n",
        "        hSample = tf.nn.relu(tf.sign(hProb0 - tf.random.uniform(tf.shape(hProb0))))\n",
        "        # Stitch it together\n",
        "        forward = tf.matmul(tf.transpose(self.X), hSample)\n",
        "\n",
        "        # Backward pass\n",
        "        # Reconstruct visible layer given hidden layer sample\n",
        "        v = tf.matmul(hSample, tf.transpose(self.weights)) + self.visibleBias\n",
        "\n",
        "        # Build up our mask for missing ratings\n",
        "        vMask = tf.sign(self.X) # Make sure everything is 0 or 1\n",
        "        vMask3D = tf.reshape(vMask, [tf.shape(v)[0], -1, self.ratingValues]) # Reshape into arrays of individual ratings\n",
        "        vMask3D = tf.reduce_max(vMask3D, axis=[2], keepdims=True) # Use reduce_max to either give us 1 for ratings that exist, and 0 for missing ratings\n",
        "\n",
        "        # Extract rating vectors for each individual set of 10 rating binary values\n",
        "        v = tf.reshape(v, [tf.shape(v)[0], -1, self.ratingValues])\n",
        "        vProb = tf.nn.softmax(v * vMask3D) # Apply softmax activation function\n",
        "        vProb = tf.reshape(vProb, [tf.shape(v)[0], -1]) # And shove them back into the flattened state. Reconstruction is done now.\n",
        "        # Stitch it together to define the backward pass and updated hidden biases\n",
        "        hProb1 = tf.nn.sigmoid(tf.matmul(vProb, self.weights) + self.hiddenBias)\n",
        "        backward = tf.matmul(tf.transpose(vProb), hProb1)\n",
        "\n",
        "        # Now define what each epoch will do...\n",
        "        # Run the forward and backward passes, and update the weights\n",
        "        weightUpdate = self.weights.assign_add(self.learningRate * (forward - backward))\n",
        "        # Update hidden bias, minimizing the divergence in the hidden nodes\n",
        "        hiddenBiasUpdate = self.hiddenBias.assign_add(self.learningRate * tf.reduce_mean(hProb0 - hProb1, 0))\n",
        "        # Update the visible bias, minimizng divergence in the visible results\n",
        "        visibleBiasUpdate = self.visibleBias.assign_add(self.learningRate * tf.reduce_mean(self.X - vProb, 0))\n",
        "\n",
        "        self.update = [weightUpdate, hiddenBiasUpdate, visibleBiasUpdate]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUN81UfznI0b"
      },
      "outputs": [],
      "source": [
        "class RBMAlgorithm(AlgoBase):\n",
        "\n",
        "    def __init__(self, epochs=20, hiddenDim=100, learningRate=0.001, batchSize=100, sim_options={}):\n",
        "        AlgoBase.__init__(self)\n",
        "        self.epochs = epochs\n",
        "        self.hiddenDim = hiddenDim\n",
        "        self.learningRate = learningRate\n",
        "        self.batchSize = batchSize\n",
        "        self.ml = MovieLens()\n",
        "        self.ml.loadMovieLensLatestSmall()\n",
        "        self.stoplist = [\"sex\", \"drugs\", \"rock n roll\"]\n",
        "\n",
        "    def buildStoplist(self, trainset):\n",
        "        self.stoplistLookup = {}\n",
        "        for iiid in trainset.all_items():\n",
        "            self.stoplistLookup[iiid] = False\n",
        "            movieID = trainset.to_raw_iid(iiid)\n",
        "            title = self.ml.getMovieName(int(movieID))\n",
        "            if (title):\n",
        "                title = title.lower()\n",
        "                for term in self.stoplist:\n",
        "                    if term in title:\n",
        "                        print (\"Blocked \", title)\n",
        "                        self.stoplistLookup[iiid] = True\n",
        "\n",
        "    def softmax(self, x):\n",
        "        return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "    def fit(self, trainset):\n",
        "        AlgoBase.fit(self, trainset)\n",
        "\n",
        "        self.buildStoplist(trainset)\n",
        "\n",
        "        numUsers = trainset.n_users\n",
        "        numItems = trainset.n_items\n",
        "\n",
        "        trainingMatrix = np.zeros([numUsers, numItems, 10], dtype=np.float32)\n",
        "\n",
        "        for (uid, iid, rating) in trainset.all_ratings():\n",
        "            if not self.stoplistLookup[iid]:\n",
        "                adjustedRating = int(float(rating)*2.0) - 1\n",
        "                trainingMatrix[int(uid), int(iid), adjustedRating] = 1\n",
        "\n",
        "        # Flatten to a 2D array, with nodes for each possible rating type on each possible item, for every user.\n",
        "        trainingMatrix = np.reshape(trainingMatrix, [trainingMatrix.shape[0], -1])\n",
        "\n",
        "        # Create an RBM with (num items * rating values) visible nodes\n",
        "        rbm = RBM(trainingMatrix.shape[1], hiddenDimensions=self.hiddenDim, learningRate=self.learningRate, batchSize=self.batchSize, epochs=self.epochs)\n",
        "        rbm.Train(trainingMatrix)\n",
        "\n",
        "        self.predictedRatings = np.zeros([numUsers, numItems], dtype=np.float32)\n",
        "        for uiid in range(trainset.n_users):\n",
        "            if (uiid % 50 == 0):\n",
        "                print(\"Processing user \", uiid)\n",
        "            recs = rbm.GetRecommendations([trainingMatrix[uiid]])\n",
        "            recs = np.reshape(recs, [numItems, 10])\n",
        "\n",
        "            for itemID, rec in enumerate(recs):\n",
        "                # The obvious thing would be to just take the rating with the highest score:\n",
        "                #rating = rec.argmax()\n",
        "                # ... but this just leads to a huge multi-way tie for 5-star predictions.\n",
        "                # The paper suggests performing normalization over K values to get probabilities\n",
        "                # and take the expectation as your prediction, so we'll do that instead:\n",
        "                normalized = self.softmax(rec)\n",
        "                rating = np.average(np.arange(10), weights=normalized)\n",
        "                self.predictedRatings[uiid, itemID] = (rating + 1) * 0.5\n",
        "\n",
        "        return self\n",
        "\n",
        "    def estimate(self, u, i):\n",
        "\n",
        "        if not (self.trainset.knows_user(u) and self.trainset.knows_item(i)):\n",
        "            raise PredictionImpossible('User and/or item is unkown.')\n",
        "\n",
        "        rating = self.predictedRatings[u, i]\n",
        "\n",
        "        if (rating < 0.001):\n",
        "            raise PredictionImpossible('No valid prediction exists.')\n",
        "\n",
        "        return rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCokGE05nQrH"
      },
      "outputs": [],
      "source": [
        "class HybridAlgorithm(AlgoBase):\n",
        "\n",
        "    def __init__(self, algorithms, weights, sim_options={}):\n",
        "        AlgoBase.__init__(self)\n",
        "        self.algorithms = algorithms\n",
        "        self.weights = weights\n",
        "\n",
        "    def fit(self, trainset):\n",
        "        AlgoBase.fit(self, trainset)\n",
        "\n",
        "        for algorithm in self.algorithms:\n",
        "            algorithm.fit(trainset)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def estimate(self, u, i):\n",
        "\n",
        "        sumScores = 0\n",
        "        sumWeights = 0\n",
        "\n",
        "        for idx in range(len(self.algorithms)):\n",
        "            sumScores += self.algorithms[idx].estimate(u, i) * self.weights[idx]\n",
        "            sumWeights += self.weights[idx]\n",
        "\n",
        "        return sumScores / sumWeights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo1gXVvanYbK",
        "outputId": "9ff342b0-3e83-44eb-93b1-66db71dc6712"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading movie ratings...\n",
            "\n",
            "Computing movie popularity ranks so we can measure novelty later...\n",
            "Estimating biases using als...\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating  Random ...\n",
            "Evaluating accuracy...\n",
            "Analysis complete.\n",
            "Evaluating  ContentKNN ...\n",
            "Evaluating accuracy...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  8211\n",
            "100  of  8211\n",
            "200  of  8211\n",
            "300  of  8211\n",
            "400  of  8211\n",
            "500  of  8211\n",
            "600  of  8211\n",
            "700  of  8211\n",
            "800  of  8211\n",
            "900  of  8211\n",
            "1000  of  8211\n",
            "1100  of  8211\n",
            "1200  of  8211\n",
            "1300  of  8211\n",
            "1400  of  8211\n",
            "1500  of  8211\n",
            "1600  of  8211\n",
            "1700  of  8211\n",
            "1800  of  8211\n",
            "1900  of  8211\n",
            "2000  of  8211\n",
            "2100  of  8211\n",
            "2200  of  8211\n",
            "2300  of  8211\n",
            "2400  of  8211\n",
            "2500  of  8211\n",
            "2600  of  8211\n",
            "2700  of  8211\n",
            "2800  of  8211\n",
            "2900  of  8211\n",
            "3000  of  8211\n",
            "3100  of  8211\n",
            "3200  of  8211\n",
            "3300  of  8211\n",
            "3400  of  8211\n",
            "3500  of  8211\n",
            "3600  of  8211\n",
            "3700  of  8211\n",
            "3800  of  8211\n",
            "3900  of  8211\n",
            "4000  of  8211\n",
            "4100  of  8211\n",
            "4200  of  8211\n",
            "4300  of  8211\n",
            "4400  of  8211\n",
            "4500  of  8211\n",
            "4600  of  8211\n",
            "4700  of  8211\n",
            "4800  of  8211\n",
            "4900  of  8211\n",
            "5000  of  8211\n",
            "5100  of  8211\n",
            "5200  of  8211\n",
            "5300  of  8211\n",
            "5400  of  8211\n",
            "5500  of  8211\n",
            "5600  of  8211\n",
            "5700  of  8211\n",
            "5800  of  8211\n",
            "5900  of  8211\n",
            "6000  of  8211\n",
            "6100  of  8211\n",
            "6200  of  8211\n",
            "6300  of  8211\n",
            "6400  of  8211\n",
            "6500  of  8211\n",
            "6600  of  8211\n",
            "6700  of  8211\n",
            "6800  of  8211\n",
            "6900  of  8211\n",
            "7000  of  8211\n",
            "7100  of  8211\n",
            "7200  of  8211\n",
            "7300  of  8211\n",
            "7400  of  8211\n",
            "7500  of  8211\n",
            "7600  of  8211\n",
            "7700  of  8211\n",
            "7800  of  8211\n",
            "7900  of  8211\n",
            "8000  of  8211\n",
            "8100  of  8211\n",
            "8200  of  8211\n",
            "...done.\n",
            "Analysis complete.\n",
            "Evaluating  SVD ...\n",
            "Evaluating accuracy...\n",
            "Analysis complete.\n",
            "Evaluating  SVD++ ...\n",
            "Evaluating accuracy...\n",
            "Analysis complete.\n",
            "Evaluating  RBM ...\n",
            "Evaluating accuracy...\n",
            "Blocked  opposite of sex, the (1998)\n",
            "Blocked  sex, lies, and videotape (1989)\n",
            "Blocked  drugstore cowboy (1989)\n",
            "Blocked  sex and lucia (lucã­a y el sexo) (2001)\n",
            "Blocked  everything you always wanted to know about sex * but were afraid to ask (1972)\n",
            "Blocked  love and other drugs (2010)\n",
            "Blocked  sex tape (2014)\n",
            "Blocked  relax... it's just sex (1998)\n",
            "Blocked  sex and the city (2008)\n",
            "Blocked  sexy beast (2000)\n",
            "Blocked  sex drive (2008)\n",
            "Blocked  midsummer night's sex comedy, a (1982)\n",
            "Blocked  sexmission (seksmisja) (1984)\n",
            "Blocked  sex ed (2014)\n",
            "Blocked  sex and the city 2 (2010)\n",
            "Blocked  the opposite sex (2014)\n",
            "Blocked  loss of sexual innocence, the (1999)\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Trained epoch  11\n",
            "Trained epoch  12\n",
            "Trained epoch  13\n",
            "Trained epoch  14\n",
            "Trained epoch  15\n",
            "Trained epoch  16\n",
            "Trained epoch  17\n",
            "Trained epoch  18\n",
            "Trained epoch  19\n",
            "Trained epoch  20\n",
            "Trained epoch  21\n",
            "Trained epoch  22\n",
            "Trained epoch  23\n",
            "Trained epoch  24\n",
            "Trained epoch  25\n",
            "Trained epoch  26\n",
            "Trained epoch  27\n",
            "Trained epoch  28\n",
            "Trained epoch  29\n",
            "Trained epoch  30\n",
            "Trained epoch  31\n",
            "Trained epoch  32\n",
            "Trained epoch  33\n",
            "Trained epoch  34\n",
            "Trained epoch  35\n",
            "Trained epoch  36\n",
            "Trained epoch  37\n",
            "Trained epoch  38\n",
            "Trained epoch  39\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Processing user  300\n",
            "Processing user  350\n",
            "Processing user  400\n",
            "Processing user  450\n",
            "Processing user  500\n",
            "Processing user  550\n",
            "Processing user  600\n",
            "Processing user  650\n",
            "Analysis complete.\n",
            "Evaluating  Hybrid ...\n",
            "Evaluating accuracy...\n",
            "Blocked  opposite of sex, the (1998)\n",
            "Blocked  sex, lies, and videotape (1989)\n",
            "Blocked  drugstore cowboy (1989)\n",
            "Blocked  sex and lucia (lucã­a y el sexo) (2001)\n",
            "Blocked  everything you always wanted to know about sex * but were afraid to ask (1972)\n",
            "Blocked  love and other drugs (2010)\n",
            "Blocked  sex tape (2014)\n",
            "Blocked  relax... it's just sex (1998)\n",
            "Blocked  sex and the city (2008)\n",
            "Blocked  sexy beast (2000)\n",
            "Blocked  sex drive (2008)\n",
            "Blocked  midsummer night's sex comedy, a (1982)\n",
            "Blocked  sexmission (seksmisja) (1984)\n",
            "Blocked  sex ed (2014)\n",
            "Blocked  sex and the city 2 (2010)\n",
            "Blocked  the opposite sex (2014)\n",
            "Blocked  loss of sexual innocence, the (1999)\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Trained epoch  11\n",
            "Trained epoch  12\n",
            "Trained epoch  13\n",
            "Trained epoch  14\n",
            "Trained epoch  15\n",
            "Trained epoch  16\n",
            "Trained epoch  17\n",
            "Trained epoch  18\n",
            "Trained epoch  19\n",
            "Trained epoch  20\n",
            "Trained epoch  21\n",
            "Trained epoch  22\n",
            "Trained epoch  23\n",
            "Trained epoch  24\n",
            "Trained epoch  25\n",
            "Trained epoch  26\n",
            "Trained epoch  27\n",
            "Trained epoch  28\n",
            "Trained epoch  29\n",
            "Trained epoch  30\n",
            "Trained epoch  31\n",
            "Trained epoch  32\n",
            "Trained epoch  33\n",
            "Trained epoch  34\n",
            "Trained epoch  35\n",
            "Trained epoch  36\n",
            "Trained epoch  37\n",
            "Trained epoch  38\n",
            "Trained epoch  39\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Processing user  300\n",
            "Processing user  350\n",
            "Processing user  400\n",
            "Processing user  450\n",
            "Processing user  500\n",
            "Processing user  550\n",
            "Processing user  600\n",
            "Processing user  650\n",
            "Computing content-based similarity matrix...\n",
            "0  of  8211\n",
            "100  of  8211\n",
            "200  of  8211\n",
            "300  of  8211\n",
            "400  of  8211\n",
            "500  of  8211\n",
            "600  of  8211\n",
            "700  of  8211\n",
            "800  of  8211\n",
            "900  of  8211\n",
            "1000  of  8211\n",
            "1100  of  8211\n",
            "1200  of  8211\n",
            "1300  of  8211\n",
            "1400  of  8211\n",
            "1500  of  8211\n",
            "1600  of  8211\n",
            "1700  of  8211\n",
            "1800  of  8211\n",
            "1900  of  8211\n",
            "2000  of  8211\n",
            "2100  of  8211\n",
            "2200  of  8211\n",
            "2300  of  8211\n",
            "2400  of  8211\n",
            "2500  of  8211\n",
            "2600  of  8211\n",
            "2700  of  8211\n",
            "2800  of  8211\n",
            "2900  of  8211\n",
            "3000  of  8211\n",
            "3100  of  8211\n",
            "3200  of  8211\n",
            "3300  of  8211\n",
            "3400  of  8211\n",
            "3500  of  8211\n",
            "3600  of  8211\n",
            "3700  of  8211\n",
            "3800  of  8211\n",
            "3900  of  8211\n",
            "4000  of  8211\n",
            "4100  of  8211\n",
            "4200  of  8211\n",
            "4300  of  8211\n",
            "4400  of  8211\n",
            "4500  of  8211\n",
            "4600  of  8211\n",
            "4700  of  8211\n",
            "4800  of  8211\n",
            "4900  of  8211\n",
            "5000  of  8211\n",
            "5100  of  8211\n",
            "5200  of  8211\n",
            "5300  of  8211\n",
            "5400  of  8211\n",
            "5500  of  8211\n",
            "5600  of  8211\n",
            "5700  of  8211\n",
            "5800  of  8211\n",
            "5900  of  8211\n",
            "6000  of  8211\n",
            "6100  of  8211\n",
            "6200  of  8211\n",
            "6300  of  8211\n",
            "6400  of  8211\n",
            "6500  of  8211\n",
            "6600  of  8211\n",
            "6700  of  8211\n",
            "6800  of  8211\n",
            "6900  of  8211\n",
            "7000  of  8211\n",
            "7100  of  8211\n",
            "7200  of  8211\n",
            "7300  of  8211\n",
            "7400  of  8211\n",
            "7500  of  8211\n",
            "7600  of  8211\n",
            "7700  of  8211\n",
            "7800  of  8211\n",
            "7900  of  8211\n",
            "8000  of  8211\n",
            "8100  of  8211\n",
            "8200  of  8211\n",
            "...done.\n",
            "Analysis complete.\n",
            "\n",
            "\n",
            "Algorithm  RMSE       MAE       \n",
            "Random     1.4385     1.1478    \n",
            "ContentKNN 0.9375     0.7263    \n",
            "SVD        0.8999     0.6960    \n",
            "SVD++      0.8959     0.6902    \n",
            "RBM        1.1892     0.9932    \n",
            "Hybrid     0.8944     0.6977    \n",
            "\n",
            "Legend:\n",
            "\n",
            "RMSE:      Root Mean Squared Error. Lower values mean better accuracy.\n",
            "MAE:       Mean Absolute Error. Lower values mean better accuracy.\n",
            "\n",
            "Using recommender  Random\n",
            "\n",
            "Building recommendation model...\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Fly, The (1986) 5\n",
            "Star Wars: Episode VI - Return of the Jedi (1983) 5\n",
            "Pet Sematary (1989) 5\n",
            "Bowling for Columbine (2002) 5\n",
            "White Stripes Under Great White Northern Lights, The (2009) 5\n",
            "Pinocchio (1940) 5\n",
            "Fox and the Hound, The (1981) 5\n",
            "Monty Python and the Holy Grail (1975) 5\n",
            "Psycho (1960) 5\n",
            "Terminator, The (1984) 5\n",
            "\n",
            "Using recommender  ContentKNN\n",
            "\n",
            "Building recommendation model...\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9066\n",
            "100  of  9066\n",
            "200  of  9066\n",
            "300  of  9066\n",
            "400  of  9066\n",
            "500  of  9066\n",
            "600  of  9066\n",
            "700  of  9066\n",
            "800  of  9066\n",
            "900  of  9066\n",
            "1000  of  9066\n",
            "1100  of  9066\n",
            "1200  of  9066\n",
            "1300  of  9066\n",
            "1400  of  9066\n",
            "1500  of  9066\n",
            "1600  of  9066\n",
            "1700  of  9066\n",
            "1800  of  9066\n",
            "1900  of  9066\n",
            "2000  of  9066\n",
            "2100  of  9066\n",
            "2200  of  9066\n",
            "2300  of  9066\n",
            "2400  of  9066\n",
            "2500  of  9066\n",
            "2600  of  9066\n",
            "2700  of  9066\n",
            "2800  of  9066\n",
            "2900  of  9066\n",
            "3000  of  9066\n",
            "3100  of  9066\n",
            "3200  of  9066\n",
            "3300  of  9066\n",
            "3400  of  9066\n",
            "3500  of  9066\n",
            "3600  of  9066\n",
            "3700  of  9066\n",
            "3800  of  9066\n",
            "3900  of  9066\n",
            "4000  of  9066\n",
            "4100  of  9066\n",
            "4200  of  9066\n",
            "4300  of  9066\n",
            "4400  of  9066\n",
            "4500  of  9066\n",
            "4600  of  9066\n",
            "4700  of  9066\n",
            "4800  of  9066\n",
            "4900  of  9066\n",
            "5000  of  9066\n",
            "5100  of  9066\n",
            "5200  of  9066\n",
            "5300  of  9066\n",
            "5400  of  9066\n",
            "5500  of  9066\n",
            "5600  of  9066\n",
            "5700  of  9066\n",
            "5800  of  9066\n",
            "5900  of  9066\n",
            "6000  of  9066\n",
            "6100  of  9066\n",
            "6200  of  9066\n",
            "6300  of  9066\n",
            "6400  of  9066\n",
            "6500  of  9066\n",
            "6600  of  9066\n",
            "6700  of  9066\n",
            "6800  of  9066\n",
            "6900  of  9066\n",
            "7000  of  9066\n",
            "7100  of  9066\n",
            "7200  of  9066\n",
            "7300  of  9066\n",
            "7400  of  9066\n",
            "7500  of  9066\n",
            "7600  of  9066\n",
            "7700  of  9066\n",
            "7800  of  9066\n",
            "7900  of  9066\n",
            "8000  of  9066\n",
            "8100  of  9066\n",
            "8200  of  9066\n",
            "8300  of  9066\n",
            "8400  of  9066\n",
            "8500  of  9066\n",
            "8600  of  9066\n",
            "8700  of  9066\n",
            "8800  of  9066\n",
            "8900  of  9066\n",
            "9000  of  9066\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Presidio, The (1988) 3.841314676872932\n",
            "Femme Nikita, La (Nikita) (1990) 3.839613347087336\n",
            "Wyatt Earp (1994) 3.8125061475551796\n",
            "Shooter, The (1997) 3.8125061475551796\n",
            "Bad Girls (1994) 3.8125061475551796\n",
            "The Hateful Eight (2015) 3.812506147555179\n",
            "True Grit (2010) 3.812506147555179\n",
            "Open Range (2003) 3.812506147555179\n",
            "Big Easy, The (1987) 3.7835412549266985\n",
            "Point Break (1991) 3.764158410102279\n",
            "\n",
            "Using recommender  SVD\n",
            "\n",
            "Building recommendation model...\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "African Queen, The (1951) 4.433596145859525\n",
            "Fight Club (1999) 4.350728534169207\n",
            "Raiders of the Lost Ark (Indiana Jones and the Raiders of the Lost Ark) (1981) 4.299920137104075\n",
            "Ran (1985) 4.293781050106315\n",
            "Once Upon a Time in America (1984) 4.291672083567783\n",
            "Chinatown (1974) 4.291332351824122\n",
            "Dark Knight, The (2008) 4.288765165286764\n",
            "Memento (2000) 4.284405155709417\n",
            "12 Angry Men (1957) 4.277235338476118\n",
            "Matrix, The (1999) 4.273248771933832\n",
            "\n",
            "Using recommender  SVD++\n",
            "\n",
            "Building recommendation model...\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Star Wars: Episode IV - A New Hope (1977) 4.5895985995101025\n",
            "Dark Knight, The (2008) 4.585486128613017\n",
            "Lock, Stock & Two Smoking Barrels (1998) 4.398693846919729\n",
            "Roger & Me (1989) 4.392542759273943\n",
            "Star Wars: Episode VI - Return of the Jedi (1983) 4.392389871033125\n",
            "Shrek (2001) 4.327390375420844\n",
            "Star Wars: Episode V - The Empire Strikes Back (1980) 4.2916592698154705\n",
            "Matrix, The (1999) 4.273190232953751\n",
            "Wallace & Gromit: A Close Shave (1995) 4.267131354015218\n",
            "Ice Age (2002) 4.253002004231735\n",
            "\n",
            "Using recommender  RBM\n",
            "\n",
            "Building recommendation model...\n",
            "Blocked  drugstore cowboy (1989)\n",
            "Blocked  love & sex (2000)\n",
            "Blocked  sex, lies, and videotape (1989)\n",
            "Blocked  sexy beast (2000)\n",
            "Blocked  sex and lucia (lucã­a y el sexo) (2001)\n",
            "Blocked  sex tape (2014)\n",
            "Blocked  everything you always wanted to know about sex * but were afraid to ask (1972)\n",
            "Blocked  opposite of sex, the (1998)\n",
            "Blocked  love and other drugs (2010)\n",
            "Blocked  sex: the annabel chong story (1999)\n",
            "Blocked  sex drive (2008)\n",
            "Blocked  sexmission (seksmisja) (1984)\n",
            "Blocked  sex and the city (2008)\n",
            "Blocked  talking about sex (1994)\n",
            "Blocked  relax... it's just sex (1998)\n",
            "Blocked  loss of sexual innocence, the (1999)\n",
            "Blocked  midsummer night's sex comedy, a (1982)\n",
            "Blocked  sex and the city 2 (2010)\n",
            "Blocked  sex ed (2014)\n",
            "Blocked  the opposite sex (2014)\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Trained epoch  11\n",
            "Trained epoch  12\n",
            "Trained epoch  13\n",
            "Trained epoch  14\n",
            "Trained epoch  15\n",
            "Trained epoch  16\n",
            "Trained epoch  17\n",
            "Trained epoch  18\n",
            "Trained epoch  19\n",
            "Trained epoch  20\n",
            "Trained epoch  21\n",
            "Trained epoch  22\n",
            "Trained epoch  23\n",
            "Trained epoch  24\n",
            "Trained epoch  25\n",
            "Trained epoch  26\n",
            "Trained epoch  27\n",
            "Trained epoch  28\n",
            "Trained epoch  29\n",
            "Trained epoch  30\n",
            "Trained epoch  31\n",
            "Trained epoch  32\n",
            "Trained epoch  33\n",
            "Trained epoch  34\n",
            "Trained epoch  35\n",
            "Trained epoch  36\n",
            "Trained epoch  37\n",
            "Trained epoch  38\n",
            "Trained epoch  39\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Processing user  300\n",
            "Processing user  350\n",
            "Processing user  400\n",
            "Processing user  450\n",
            "Processing user  500\n",
            "Processing user  550\n",
            "Processing user  600\n",
            "Processing user  650\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Howl's Moving Castle (Hauru no ugoku shiro) (2004) 3.3555386\n",
            "Hurt Locker, The (2008) 3.355505\n",
            "Harry Potter and the Half-Blood Prince (2009) 3.355243\n",
            "Downfall (Untergang, Der) (2004) 3.3548331\n",
            "Harry Potter and the Deathly Hallows: Part 2 (2011) 3.353954\n",
            "On the Waterfront (1954) 3.3467245\n",
            "Maltese Falcon, The (a.k.a. Dangerous Female) (1931) 3.3456066\n",
            "NausicaÃ¤ of the Valley of the Wind (Kaze no tani no Naushika) (1984) 3.3439505\n",
            "You Can Count on Me (2000) 3.3428242\n",
            "Amores Perros (Love's a Bitch) (2000) 3.3390105\n",
            "\n",
            "Using recommender  Hybrid\n",
            "\n",
            "Building recommendation model...\n",
            "Blocked  drugstore cowboy (1989)\n",
            "Blocked  love & sex (2000)\n",
            "Blocked  sex, lies, and videotape (1989)\n",
            "Blocked  sexy beast (2000)\n",
            "Blocked  sex and lucia (lucã­a y el sexo) (2001)\n",
            "Blocked  sex tape (2014)\n",
            "Blocked  everything you always wanted to know about sex * but were afraid to ask (1972)\n",
            "Blocked  opposite of sex, the (1998)\n",
            "Blocked  love and other drugs (2010)\n",
            "Blocked  sex: the annabel chong story (1999)\n",
            "Blocked  sex drive (2008)\n",
            "Blocked  sexmission (seksmisja) (1984)\n",
            "Blocked  sex and the city (2008)\n",
            "Blocked  talking about sex (1994)\n",
            "Blocked  relax... it's just sex (1998)\n",
            "Blocked  loss of sexual innocence, the (1999)\n",
            "Blocked  midsummer night's sex comedy, a (1982)\n",
            "Blocked  sex and the city 2 (2010)\n",
            "Blocked  sex ed (2014)\n",
            "Blocked  the opposite sex (2014)\n",
            "Trained epoch  0\n",
            "Trained epoch  1\n",
            "Trained epoch  2\n",
            "Trained epoch  3\n",
            "Trained epoch  4\n",
            "Trained epoch  5\n",
            "Trained epoch  6\n",
            "Trained epoch  7\n",
            "Trained epoch  8\n",
            "Trained epoch  9\n",
            "Trained epoch  10\n",
            "Trained epoch  11\n",
            "Trained epoch  12\n",
            "Trained epoch  13\n",
            "Trained epoch  14\n",
            "Trained epoch  15\n",
            "Trained epoch  16\n",
            "Trained epoch  17\n",
            "Trained epoch  18\n",
            "Trained epoch  19\n",
            "Trained epoch  20\n",
            "Trained epoch  21\n",
            "Trained epoch  22\n",
            "Trained epoch  23\n",
            "Trained epoch  24\n",
            "Trained epoch  25\n",
            "Trained epoch  26\n",
            "Trained epoch  27\n",
            "Trained epoch  28\n",
            "Trained epoch  29\n",
            "Trained epoch  30\n",
            "Trained epoch  31\n",
            "Trained epoch  32\n",
            "Trained epoch  33\n",
            "Trained epoch  34\n",
            "Trained epoch  35\n",
            "Trained epoch  36\n",
            "Trained epoch  37\n",
            "Trained epoch  38\n",
            "Trained epoch  39\n",
            "Processing user  0\n",
            "Processing user  50\n",
            "Processing user  100\n",
            "Processing user  150\n",
            "Processing user  200\n",
            "Processing user  250\n",
            "Processing user  300\n",
            "Processing user  350\n",
            "Processing user  400\n",
            "Processing user  450\n",
            "Processing user  500\n",
            "Processing user  550\n",
            "Processing user  600\n",
            "Processing user  650\n",
            "Computing content-based similarity matrix...\n",
            "0  of  9066\n",
            "100  of  9066\n",
            "200  of  9066\n",
            "300  of  9066\n",
            "400  of  9066\n",
            "500  of  9066\n",
            "600  of  9066\n",
            "700  of  9066\n",
            "800  of  9066\n",
            "900  of  9066\n",
            "1000  of  9066\n",
            "1100  of  9066\n",
            "1200  of  9066\n",
            "1300  of  9066\n",
            "1400  of  9066\n",
            "1500  of  9066\n",
            "1600  of  9066\n",
            "1700  of  9066\n",
            "1800  of  9066\n",
            "1900  of  9066\n",
            "2000  of  9066\n",
            "2100  of  9066\n",
            "2200  of  9066\n",
            "2300  of  9066\n",
            "2400  of  9066\n",
            "2500  of  9066\n",
            "2600  of  9066\n",
            "2700  of  9066\n",
            "2800  of  9066\n",
            "2900  of  9066\n",
            "3000  of  9066\n",
            "3100  of  9066\n",
            "3200  of  9066\n",
            "3300  of  9066\n",
            "3400  of  9066\n",
            "3500  of  9066\n",
            "3600  of  9066\n",
            "3700  of  9066\n",
            "3800  of  9066\n",
            "3900  of  9066\n",
            "4000  of  9066\n",
            "4100  of  9066\n",
            "4200  of  9066\n",
            "4300  of  9066\n",
            "4400  of  9066\n",
            "4500  of  9066\n",
            "4600  of  9066\n",
            "4700  of  9066\n",
            "4800  of  9066\n",
            "4900  of  9066\n",
            "5000  of  9066\n",
            "5100  of  9066\n",
            "5200  of  9066\n",
            "5300  of  9066\n",
            "5400  of  9066\n",
            "5500  of  9066\n",
            "5600  of  9066\n",
            "5700  of  9066\n",
            "5800  of  9066\n",
            "5900  of  9066\n",
            "6000  of  9066\n",
            "6100  of  9066\n",
            "6200  of  9066\n",
            "6300  of  9066\n",
            "6400  of  9066\n",
            "6500  of  9066\n",
            "6600  of  9066\n",
            "6700  of  9066\n",
            "6800  of  9066\n",
            "6900  of  9066\n",
            "7000  of  9066\n",
            "7100  of  9066\n",
            "7200  of  9066\n",
            "7300  of  9066\n",
            "7400  of  9066\n",
            "7500  of  9066\n",
            "7600  of  9066\n",
            "7700  of  9066\n",
            "7800  of  9066\n",
            "7900  of  9066\n",
            "8000  of  9066\n",
            "8100  of  9066\n",
            "8200  of  9066\n",
            "8300  of  9066\n",
            "8400  of  9066\n",
            "8500  of  9066\n",
            "8600  of  9066\n",
            "8700  of  9066\n",
            "8800  of  9066\n",
            "8900  of  9066\n",
            "9000  of  9066\n",
            "...done.\n",
            "Computing recommendations...\n",
            "\n",
            "We recommend:\n",
            "Snatch (2000) 3.9014268903703084\n",
            "Indiana Jones and the Last Crusade (1989) 3.8998079732037545\n",
            "City of God (Cidade de Deus) (2002) 3.8959672235267173\n",
            "Grand Day Out with Wallace and Gromit, A (1989) 3.8780820289455815\n",
            "Lock, Stock & Two Smoking Barrels (1998) 3.871519787092448\n",
            "Harry Potter and the Deathly Hallows: Part 2 (2011) 3.867665746197407\n",
            "African Queen, The (1951) 3.856634000225563\n",
            "Usual Suspects, The (1995) 3.85275110088714\n",
            "Happiness (1998) 3.8501096681793796\n",
            "Harry Potter and the Half-Blood Prince (2009) 3.8479129318314063\n"
          ]
        }
      ],
      "source": [
        "def LoadMovieLensData():\n",
        "    ml = MovieLens()\n",
        "    print(\"Loading movie ratings...\")\n",
        "    data = ml.loadMovieLensLatestSmall()\n",
        "    print(\"\\nComputing movie popularity ranks so we can measure novelty later...\")\n",
        "    rankings = ml.getPopularityRanks()\n",
        "    return (ml, data, rankings)\n",
        "\n",
        "np.random.seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "# Load up common data set for the recommender algorithms\n",
        "(ml, evaluationData, rankings) = LoadMovieLensData()\n",
        "\n",
        "# Construct an Evaluator to, you know, evaluate them\n",
        "evaluator = Evaluator(evaluationData, rankings)\n",
        "\n",
        "# Just make random recommendations\n",
        "Random = NormalPredictor()\n",
        "# Simple RBM\n",
        "SimpleRBM = RBMAlgorithm(epochs=40)\n",
        "# Content\n",
        "ContentKNN = ContentKNNAlgorithm()\n",
        "# SVD\n",
        "SVD = SVD(n_epochs=20, lr_all=0.005, n_factors=50)\n",
        "# SVD++\n",
        "SVDPlusPlus = SVDpp()\n",
        "\n",
        "#Combine them\n",
        "Hybrid = HybridAlgorithm([SimpleRBM, ContentKNN, SVD, SVDPlusPlus], [0.1, 0.25, 0.3, 0.35])\n",
        "\n",
        "evaluator.AddAlgorithm(Random, \"Random\")\n",
        "evaluator.AddAlgorithm(ContentKNN, \"ContentKNN\")\n",
        "evaluator.AddAlgorithm(SVD, \"SVD\")\n",
        "evaluator.AddAlgorithm(SVDPlusPlus, \"SVD++\")\n",
        "evaluator.AddAlgorithm(SimpleRBM, \"RBM\")\n",
        "evaluator.AddAlgorithm(Hybrid, \"Hybrid\")\n",
        "\n",
        "evaluator.Evaluate(False)\n",
        "\n",
        "evaluator.SampleTopNRecs(ml, 85)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
